# import os, logging, re, requests, chromadb, numpy as np
# import torch
# from rasa_sdk import Action, Tracker
# from rasa_sdk.executor import CollectingDispatcher
# from sentence_transformers import SentenceTransformer
# from dotenv import load_dotenv

# # ุฅุนุฏุงุฏ ุงูููุฌ
# logger = logging.getLogger(__name__)
# logging.basicConfig(level=logging.INFO)

# # ุชุญููู ุงููุชุบูุฑุงุช
# load_dotenv()
# API_KEY = os.getenv("OPENROUTER_API_KEY")

# # ููุฏูู ุงูุชุถููู
# embedder = SentenceTransformer("intfloat/multilingual-e5-large")

# def encode(text, is_query=True):
#     with torch.no_grad():
#         return embedder.encode(text, convert_to_numpy=True).astype("float32")

# # ChromaDB
# client = chromadb.PersistentClient(path="chroma_db")
# faq_collection = client.get_collection("faq_only")

# NON_ACADEMIC_PHRASES = ["ุงุณูู", "ุงุฎุจุงุฑู", "ุญุจูุจู", "ุจุชุญุจูู", "ูุณุงุก ุงูุฎูุฑ", "ุตุจุงุญ ุงูุฎูุฑ"]

# def is_academic_question(text):
#     return not any(p in text.lower() for p in NON_ACADEMIC_PHRASES)

# def shorten(text, max_sentences=2):
#     sentences = re.split(r'(?<=[.!ุ])\s+', text)
#     return ' '.join(sentences[:max_sentences]).strip()

# def retrieve_context(collection, question, top_k=4, threshold=0.3):
#     query_emb = encode(question).tolist()
#     result = collection.query(
#         query_embeddings=[query_emb],
#         n_results=top_k,
#         include=["documents", "embeddings"]
#     )
#     docs = result.get("documents", [[]])[0]
#     embs = result.get("embeddings", [[]])[0]

#     if not docs:
#         return []

#     scored = []
#     for doc, emb in zip(docs, embs):
#         sim = np.dot(query_emb, emb) / (np.linalg.norm(query_emb) * np.linalg.norm(emb))
#         if sim >= threshold:
#             scored.append((sim, doc))

#     return sorted(scored, key=lambda x: x[0], reverse=True)

# def rephrase_with_model(text, question):
#     prompt = f"""ุฃูุช ูุณุงุนุฏ ุฌุงูุนู ุฐูู ููุชุฎุตุต ูู ุงูุฑุฏ ุนูู ุงุณุชูุณุงุฑุงุช ุงูุทูุงุจ ุญูู ูููุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู.
#     ูููุชู ูู ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุฅุฌุงุจุงุช ุจุดูู ุฃูุงุฏููู ูุงุถุญุ ูุจุฃุณููุจ ูุจุณุท ูุณูู ูููู ุฎุงุตุฉ ููุทูุงุจ ุงูุฌุฏุฏ ุฃู ุงูููุจููู ุนูู ุงูุงูุชุญุงู ุจุงููููุฉ.
#     ุงุญุฑุต ุนูู ุฃู ุชููู ุงูุฅุฌุงุจุฉ ุดุงููุฉ ุชูุงููุงุ ููุง ุชุฎุชุตุฑ ุฃู ุชุญุฐู ุฃู ูุนูููุฉุ ุจู ูุถูุญูุง ุจุดูู ุฃูุถู ูุน ุงูุญูุงุธ ุนูู ุงููุนูู ุงูุฃุตูู.
#     ุฅุฐุง ูุงุญุธุช ุฃู ุงูุฅุฌุงุจุฉ ูุง ุชุญุชูู ุนูู ูุนูููุงุช ูุงููุฉุ ุฃุถู ูู ููุงูุชูุง ุชููููุงู ููุฐุจุงู ูุดูุฑ ุฅูู ุถุฑูุฑุฉ ุงูุฑุฌูุน ุฅูู ุฅุฏุงุฑุฉ ุงููููุฉ ุฃู ุงูุฌูุฉ ุงููุฎุชุตุฉ.

#     ุงูุณุคุงู: {question}
#     ุงูุฅุฌุงุจุฉ ุงูุฃูููุฉ: {text}

#     ุฃุนุฏ ุตูุงุบุฉ ุงูุฅุฌุงุจุฉ ูุงููุฉ ุจุดูู ูุงุถุญ ูุณูุณ ูุจุฏูู ุฃู ุงุฎุชุตุงุฑุ ูุน ุงูุงูุชุฒุงู ุจุงูุชุนูููุงุช ุฃุนูุงู."""


#     try:
#         r = requests.post(
#             "https://openrouter.ai/api/v1/chat/completions",
#             headers={"Authorization": f"Bearer {API_KEY}"},
#             json={
#                 "model": "openai/gpt-3.5-turbo",
#                 "messages": [
#                     {"role": "system", "content": "ุฃุนุฏ ุตูุงุบุฉ ุฅุฌุงุจุฉ ุงูุทุงูุจ ุจุดูู ุฃูุงุฏููู ูุงุถุญ"},
#                     {"role": "user", "content": prompt}
#                 ]
#             }
#         )
#         if r.status_code == 200:
#             return shorten(r.json()["choices"][0]["message"]["content"].strip())
#         else:
#             logger.error(f"Rephrase Error: {r.status_code} - {r.text}")
#             return shorten(text)
#     except Exception as e:
#         logger.exception("ุฎุทุฃ ูู ุงูุงุชุตุงู ุจู LLM.")
#         return shorten(text)


# class ActionRAG(Action):
#     def name(self):
#         return "action_rag_answer"

#     def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: dict):
#         question = tracker.latest_message.get("text", "").strip()
#         logger.info(f"๐ฅ ุณุคุงู ุงููุณุชุฎุฏู: {question}")

#         if len(question.split()) < 2:
#             dispatcher.utter_message("ูู ูุถููุ ุงูุชุจ ุณุคุงูู ุจุดูู ูุงุถุญ.")
#             return []

#         if not is_academic_question(question):
#             dispatcher.utter_message("ุฃูุง ููุง ููุฑุฏ ุนูู ุงุณุชูุณุงุฑุงุช ุงููููุฉ ููุท ๐")
#             return []

#         results = retrieve_context(faq_collection, question)

#         if not results:
#             dispatcher.utter_message("ูู ุฃุฌุฏ ูุนูููุงุช ูุงููุฉ ููุฅุฌุงุจุฉ ุนูู ุณุคุงูู.")
#             return []

#         best_score, best_doc = results[0]
#         logger.info(f"โ ุฃูุถู ูุชูุฌุฉ - Score: {best_score:.4f}")
#         answer = rephrase_with_model(best_doc, question)
#         dispatcher.utter_message(answer)
#         return []




import os, logging, re, requests, chromadb, numpy as np
import torch
from rasa_sdk import Action, Tracker
from rasa_sdk.executor import CollectingDispatcher
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# ุฅุนุฏุงุฏ ุงูููุฌ
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ุชุญููู ุงููุชุบูุฑุงุช
load_dotenv(os.path.join(os.path.dirname(__file__), ".env"))
API_KEY = os.getenv("OPENROUTER_API_KEY")

# ููุฏูู ุงูุชุถููู
embedder = SentenceTransformer("intfloat/multilingual-e5-large")

def encode(text):
    with torch.no_grad():
        return embedder.encode(text, convert_to_numpy=True).astype("float32")

# ChromaDB
client = chromadb.PersistentClient(path="chroma_db")
faq_collection = client.get_collection("faq_only")

# ุนุจุงุฑุงุช ุบูุฑ ุฃูุงุฏูููุฉ
NON_ACADEMIC_PHRASES = ["ุงุณูู", "ุงุฎุจุงุฑู", "ุญุจูุจู", "ุจุชุญุจูู", "ูุณุงุก ุงูุฎูุฑ", "ุตุจุงุญ ุงูุฎูุฑ"]

def is_academic_question(text):
    return not any(p in text.lower() for p in NON_ACADEMIC_PHRASES)

def shorten(text, max_sentences=5):
    sentences = re.split(r'(?<=[.!ุ])\s+', text)
    return ' '.join(sentences[:max_sentences]).strip()

def retrieve_context(collection, question, top_k=4, threshold=0.35):
    query_emb = encode(question).tolist()
    result = collection.query(
        query_embeddings=[query_emb],
        n_results=top_k,
        include=["documents", "embeddings"]
    )
    docs = result.get("documents", [[]])[0]
    embs = result.get("embeddings", [[]])[0]

    if not docs:
        return []

    scored = []
    for doc, emb in zip(docs, embs):
        sim = np.dot(query_emb, emb) / (np.linalg.norm(query_emb) * np.linalg.norm(emb))
        if sim >= threshold:
            scored.append((sim, doc))

    return sorted(scored, key=lambda x: x[0], reverse=True)

def extract_memory_context(tracker: Tracker, max_turns=2):
    memory = []
    events = tracker.events[::-1]
    turns = 0
    last_user = ""
    last_bot = ""
    for event in events:
        if event.get("event") == "bot":
            last_bot = event.get("text", "")
        elif event.get("event") == "user":
            last_user = event.get("text", "")
            if last_user and last_bot:
                memory.append(f"ุณุคุงู ุณุงุจู: {last_user}\nุงูุฅุฌุงุจุฉ: {last_bot}")
                turns += 1
                last_user = ""
                last_bot = ""
                if turns >= max_turns:
                    break
    return "\n\n".join(memory[::-1])  # ุงูุฃูุฏู ุฃูููุง

def rephrase_with_model(text, question, memory=""):
    table_hint = """
ูุฑูู ุฃุฏูุงู ุฌุฏูู ููุงุฏ ูุงุฆุญุฉ ุงููููุฉ ูุตูุญุงุชูุง:

- ุชูููุฏ โ ุตูุญุฉ 3
- ุฃูุฏุงู ุงููููุฉ โ ุตูุญุฉ 4
- ููุญู (1): ูููุฐุฌ ุงูุฎุทุฉ ุงูุฏุฑุงุณูุฉ ููููุฑุฑุงุช โ ุตูุญุฉ 42
- ููุญู (2): ูุตู ุงูููุฑุฑุงุช โ ุตูุญุฉ 50
- ูุงุฏุฉ (1): ููุงุนุฏ ุงููุจูู โ ุตูุญุฉ 5
- ูุงุฏุฉ (2): ุฃูุณุงู ุงููููุฉ โ ุตูุญุฉ 5
- ูุงุฏุฉ (3): ุงูุฏุฑุฌุงุช ุงูุนูููุฉ โ ุตูุญุฉ 10
- ูุงุฏุฉ (4): ูุบุฉ ุงูุชุฏุฑูุณ โ ุตูุญุฉ 11
- ูุงุฏุฉ (5): ุงูุชุนููู ุนู ุจุนุฏ โ ุตูุญุฉ 11
- ูุงุฏุฉ (6): ูุธุงู ุงูุฏุฑุงุณุฉ โ ุตูุญุฉ 11
- ูุงุฏุฉ (7): ุงูุฅุฑุดุงุฏ ุงูุฃูุงุฏููู โ ุตูุญุฉ 12
- ูุงุฏุฉ (8): ุงูุชุณุฌูู ูุงูุญุฐู ูุงูุฅุถุงูุฉ โ ุตูุญุฉ 12
- ูุงุฏุฉ (9): ุงูุงูุณุญุงุจ ูู ุงูููุฑุฑ โ ุตูุญุฉ 13
- ูุงุฏุฉ (10): ุงูุบูุงุจ ูุงูููุงุธุจุฉ โ ุตูุญุฉ 13
- ูุงุฏุฉ (11): ุงูุงููุทุงุน ุนู ุงูุฏุฑุงุณุฉ โ ุตูุญุฉ 14
- ูุงุฏุฉ (12): ุงููุตู ูู ุงููููุฉ โ ุตูุญุฉ 14
- ูุงุฏุฉ (13): ุงูุงูุชูุงู ุจูู ุงููุณุชููุงุช โ ุตูุญุฉ 15
- ูุงุฏุฉ (14): ุงูุชุญููู ูู ูููุงุช ุฃุฎุฑู โ ุตูุญุฉ 15
- ูุงุฏุฉ (15): ูุธุงู ุงูุงูุชุญุงูุงุช โ ุตูุญุฉ 15
- ูุงุฏุฉ (16): ูุธุงู ุงูุชูููู โ ุตูุญุฉ 16
- ูุงุฏุฉ (17): ุงูุฑุณูุจ ูุงูุฅุนุงุฏุฉ โ ุตูุญุฉ 17
- ูุงุฏุฉ (18): ูุดุฑูุน ุงูุชุฎุฑุฌ โ ุตูุญุฉ 18
- ูุงุฏุฉ (19): ุงูุชุฏุฑูุจ ุงูุนููู ูุงูููุฏุงูู โ ุตูุญุฉ 18
- ูุงุฏุฉ (20): ุฑุณูู ุงูุฏุฑุงุณุฉ โ ุตูุญุฉ 18
- ูุงุฏุฉ (21): ุงูููุญ ุงูุฏุฑุงุณูุฉ โ ุตูุญุฉ 19
- ูุงุฏุฉ (22): ุฏุนู ุงูุทูุงุจ โ ุตูุญุฉ 19
- ูุงุฏุฉ (23): ูุธุงู ุงูุงุณุชูุงุน โ ุตูุญุฉ 20
- ูุงุฏุฉ (25): ูุฌูุณ ุฅุฏุงุฑุฉ ุงูุจุฑุงูุฌ ุงููููุฒุฉ โ ุตูุญุฉ 21
- ูุงุฏุฉ (26): ุฃุญูุงู ุชูุธูููุฉ โ ุตูุญุฉ 22
- ูุงุฏุฉ (27): ูุชุทูุจุงุช ุงูุฏุฑุงุณุฉ โ ุตูุญุฉ 22
- ุงููุชุทูุจุงุช ุงูุนุงูุฉ โ ุตูุญุฉ 24
- ูุชุทูุจุงุช ุงููููุฉ โ ุตูุญุฉ 25
- ูุชุทูุจุงุช ุงูุชุฎุตุต โ ุตูุญุฉ 29
"""

    prompt = f"""ุฃูุช ูุณุงุนุฏ ุฌุงูุนู ุฐูู ููุชุฎุตุต ูู ุงูุฑุฏ ุนูู ุงุณุชูุณุงุฑุงุช ุงูุทูุงุจ ุญูู ูููุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู.
ูููุชู ูู ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุฅุฌุงุจุงุช ุจุดูู ุฃูุงุฏููู ูุงุถุญุ ูุจุฏูู ุงุฎุชุตุงุฑ ุฃู ุญุฐู ูููุนูููุงุชุ ูุน ุชูุถูุญ ุฃู ููุงุท ุบุงูุถุฉ ูุชููู ูููููุฉ ููุทูุงุจ ุงูุฌุฏุฏ.
ุฅุฐุง ูุงูุช ููุงู ุฅุฌุงุจุฉ ุบูุฑ ูุงููุฉุ ุฃุถู ููุงุญุธุฉ ููุฐุจุฉ ุชุญุซ ุงูุทุงูุจ ุนูู ุงูุฑุฌูุน ูุฅุฏุงุฑุฉ ุงููููุฉ.
ุฅุฐุง ูุงูุช ุงูุฅุฌุงุจุฉ ุชุชุนูู ุจููุถูุน ูุฐููุฑ ูู ุงููุงุฆุญุฉุ ูุฃุถู ูู ุงูููุงูุฉ (ุงููุตุฏุฑ: ูุงุฏุฉ ุฃู ููุญู ุฑูู X - ุตูุญุฉ Y ูู ุงููุงุฆุญุฉ ุงูุฏุฑุงุณูุฉ).

{table_hint}

ุงูุณูุงู ุงูุณุงุจู:
{memory}

ุงูุณุคุงู ุงูุญุงูู: {question}
ุงูุฅุฌุงุจุฉ ุงูุฃูููุฉ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช: {text}

ุฃุนุฏ ุตูุงุบุฉ ุงูุฅุฌุงุจุฉ ูุงููุฉ ูุจุฏูู ุงุฎุชุตุงุฑ ูุจุฃุณููุจ ุฃูุงุฏููู ูุงุถุญ.
"""

    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://your-app.com",
                "X-Title": "TestBot"
            },
            json={
                "model": "google/gemini-2.0-flash-001",
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 1000
            }
        )

        if response.status_code == 200:
            return shorten(response.json()["choices"][0]["message"]["content"].strip(), 7)
        else:
            logger.error(f"โ Gemini Error {response.status_code}: {response.text}")
            return shorten(text)
    except Exception as e:
        logger.exception("โ๏ธ ุฎุทุฃ ูู ุงูุงุชุตุงู ุจู Gemini.")
        return shorten(text)

class ActionRAGAnswer(Action):
    def name(self):
        return "action_rag_answer"

    def run(self, dispatcher: CollectingDispatcher, tracker: Tracker, domain: dict):
        question = tracker.latest_message.get("text", "").strip()
        logger.info(f"๐ฅ ุณุคุงู ุงููุณุชุฎุฏู: {question}")

        if len(question.split()) < 2:
            dispatcher.utter_message("ูู ูุถููุ ุงูุชุจ ุณุคุงูู ุจุดูู ูุงุถุญ.")
            return []

        if not is_academic_question(question):
            dispatcher.utter_message("ุฃูุง ููุง ููุฑุฏ ุนูู ุงุณุชูุณุงุฑุงุช ุงููููุฉ ููุท ๐")
            return []

        results = retrieve_context(faq_collection, question)

        if not results:
            dispatcher.utter_message("ูู ุฃุฌุฏ ูุนูููุงุช ูุงููุฉ ููุฅุฌุงุจุฉ ุนูู ุณุคุงูู.")
            return []

        best_score, best_doc = results[0]
        logger.info(f"โ ุฃูุถู ูุชูุฌุฉ - Score: {best_score:.4f}")
        answer = rephrase_with_model(best_doc, question)
        dispatcher.utter_message(answer)
        return []
    
